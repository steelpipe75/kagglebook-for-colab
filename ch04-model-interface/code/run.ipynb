{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steelpipe75/kagglebook-for-colab/blob/master/ch04-model-interface/code/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c94975d0",
      "metadata": {
        "id": "c94975d0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Google Colab 上で実行しているかどうかを判断するフラグ\n",
        "ON_COLAB = \"google.colab\" in sys.modules\n",
        "print(f\"ON_COLAB: {ON_COLAB}\")\n",
        "\n",
        "if ON_COLAB:\n",
        "    # USE_KAGGLE_GIT = True # Kaggle-cli,Gitを使う\n",
        "    USE_KAGGLE_GIT = False # Kaggle-cli,Gitを使わない\n",
        "\n",
        "    import sys\n",
        "    import os\n",
        "    import zipfile\n",
        "\n",
        "    os.makedirs('/content/input/', exist_ok=True)\n",
        "\n",
        "    print(f\"USE_KAGGLE_GIT: {USE_KAGGLE_GIT}\")\n",
        "    if USE_KAGGLE_GIT:\n",
        "        import json\n",
        "        from google.colab import userdata\n",
        "        # シークレットからKAGGLE_USERNAMEとKAGGLE_KEYを取得\n",
        "        KAGGLE_USERNAME = userdata.get('KAGGLE_USERNAME')\n",
        "        KAGGLE_KEY = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "        # kaggle.jsonファイルを作成\n",
        "        kaggle_credentials = {\"username\": KAGGLE_USERNAME, \"key\": KAGGLE_KEY}\n",
        "        with open(\"kaggle.json\", \"w\") as f:\n",
        "            json.dump(kaggle_credentials, f)\n",
        "\n",
        "        # kaggle.jsonファイルを~/.kaggleディレクトリに移動し、パーミッションを設定\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !mv kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "        # Kaggle APIをインストール\n",
        "        %pip install kaggle\n",
        "        !kaggle competitions download -c otto-group-product-classification-challenge\n",
        "\n",
        "        zip_path = '/content/otto-group-product-classification-challenge.zip'\n",
        "\n",
        "        !git clone https://github.com/steelpipe75/kagglebook-for-colab.git\n",
        "\n",
        "        sys.path.append('/content/kagglebook-for-colab/ch04-model-interface/code')\n",
        "    else:\n",
        "        # Google Drive にマウントする\n",
        "        drive = importlib.import_module(\"google.colab.drive\")\n",
        "        drive.mount(\"/content/drive/\")\n",
        "\n",
        "        colab_dir = \"/content/drive/MyDrive/kagglebook/\" # データ置き場\n",
        "        sys.path.append(os.path.join(colab_dir, 'ch04-model-interface/code'))\n",
        "\n",
        "        zip_path = os.path.join(colab_dir, 'ch04-model-interface/input/otto-group-product-classification-challenge.zip')\n",
        "\n",
        "    extract_to = '/content/input/'\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "    # titanic.zipが存在するか確認\n",
        "    if os.path.exists(zip_path):\n",
        "        # titanic.zipを展開\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"{zip_path}を展開しました。\")\n",
        "    else:\n",
        "        print(f\"{zip_path}が見つかりません。\")"
      ],
      "metadata": {
        "id": "rBL-veYgY2zs",
        "outputId": "26c9cf3f-3491-4989-e345-38020cde2471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rBL-veYgY2zs",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ON_COLAB: True\n",
            "USE_KAGGLE_GIT: False\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/kagglebook/ch04-model-interface/input/otto-group-product-classification-challenge.zipを展開しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d02d1497",
      "metadata": {
        "id": "d02d1497"
      },
      "outputs": [],
      "source": [
        "from model_nn import ModelNN\n",
        "from model_xgb import ModelXGB\n",
        "from runner import Runner\n",
        "from util import Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec77dcf6",
      "metadata": {
        "id": "ec77dcf6",
        "outputId": "59a7e566-75ae-48ed-885b-e91385b38447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-04-07 11:29:25] - xgb1 - start training cv\n",
            "INFO:general:[2025-04-07 11:29:25] - xgb1 - start training cv\n",
            "[2025-04-07 11:29:25] - xgb1 fold 0 - start training\n",
            "INFO:general:[2025-04-07 11:29:25] - xgb1 fold 0 - start training\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:29:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.95434\teval-mlogloss:1.96217\n",
            "[1]\ttrain-mlogloss:1.77924\teval-mlogloss:1.79236\n",
            "[2]\ttrain-mlogloss:1.63447\teval-mlogloss:1.65303\n",
            "[3]\ttrain-mlogloss:1.51706\teval-mlogloss:1.54080\n",
            "[4]\ttrain-mlogloss:1.41458\teval-mlogloss:1.44290\n",
            "[5]\ttrain-mlogloss:1.32641\teval-mlogloss:1.36052\n",
            "[6]\ttrain-mlogloss:1.25102\teval-mlogloss:1.28936\n",
            "[7]\ttrain-mlogloss:1.18227\teval-mlogloss:1.22500\n",
            "[8]\ttrain-mlogloss:1.11943\teval-mlogloss:1.16655\n",
            "[9]\ttrain-mlogloss:1.06496\teval-mlogloss:1.11644\n",
            "[10]\ttrain-mlogloss:1.01400\teval-mlogloss:1.06974\n",
            "[11]\ttrain-mlogloss:0.96926\teval-mlogloss:1.02853\n",
            "[12]\ttrain-mlogloss:0.92791\teval-mlogloss:0.99058\n",
            "[13]\ttrain-mlogloss:0.89194\teval-mlogloss:0.95777\n",
            "[14]\ttrain-mlogloss:0.85757\teval-mlogloss:0.92695\n",
            "[15]\ttrain-mlogloss:0.82626\teval-mlogloss:0.89882\n",
            "[16]\ttrain-mlogloss:0.79730\teval-mlogloss:0.87269\n",
            "[17]\ttrain-mlogloss:0.77083\teval-mlogloss:0.84925\n",
            "[18]\ttrain-mlogloss:0.74605\teval-mlogloss:0.82755\n",
            "[19]\ttrain-mlogloss:0.72409\teval-mlogloss:0.80806\n",
            "[20]\ttrain-mlogloss:0.70265\teval-mlogloss:0.78888\n",
            "[21]\ttrain-mlogloss:0.68229\teval-mlogloss:0.77096\n",
            "[22]\ttrain-mlogloss:0.66486\teval-mlogloss:0.75564\n",
            "[23]\ttrain-mlogloss:0.64868\teval-mlogloss:0.74148\n",
            "[24]\ttrain-mlogloss:0.63210\teval-mlogloss:0.72708\n",
            "[25]\ttrain-mlogloss:0.61704\teval-mlogloss:0.71424\n",
            "[26]\ttrain-mlogloss:0.60324\teval-mlogloss:0.70278\n",
            "[27]\ttrain-mlogloss:0.58930\teval-mlogloss:0.69119\n",
            "[28]\ttrain-mlogloss:0.57612\teval-mlogloss:0.68008\n",
            "[29]\ttrain-mlogloss:0.56415\teval-mlogloss:0.67021\n",
            "[30]\ttrain-mlogloss:0.55320\teval-mlogloss:0.66093\n",
            "[31]\ttrain-mlogloss:0.54343\teval-mlogloss:0.65311\n",
            "[32]\ttrain-mlogloss:0.53363\teval-mlogloss:0.64503\n",
            "[33]\ttrain-mlogloss:0.52441\teval-mlogloss:0.63766\n",
            "[34]\ttrain-mlogloss:0.51608\teval-mlogloss:0.63089\n",
            "[35]\ttrain-mlogloss:0.50789\teval-mlogloss:0.62419\n",
            "[36]\ttrain-mlogloss:0.50043\teval-mlogloss:0.61823\n",
            "[37]\ttrain-mlogloss:0.49294\teval-mlogloss:0.61236\n",
            "[38]\ttrain-mlogloss:0.48573\teval-mlogloss:0.60653\n",
            "[39]\ttrain-mlogloss:0.47930\teval-mlogloss:0.60148\n",
            "[40]\ttrain-mlogloss:0.47357\teval-mlogloss:0.59698\n",
            "[41]\ttrain-mlogloss:0.46774\teval-mlogloss:0.59251\n",
            "[42]\ttrain-mlogloss:0.46211\teval-mlogloss:0.58823\n",
            "[43]\ttrain-mlogloss:0.45674\teval-mlogloss:0.58415\n",
            "[44]\ttrain-mlogloss:0.45142\teval-mlogloss:0.58025\n",
            "[45]\ttrain-mlogloss:0.44609\teval-mlogloss:0.57647\n",
            "[46]\ttrain-mlogloss:0.44130\teval-mlogloss:0.57299\n",
            "[47]\ttrain-mlogloss:0.43649\teval-mlogloss:0.56958\n",
            "[48]\ttrain-mlogloss:0.43206\teval-mlogloss:0.56649\n",
            "[49]\ttrain-mlogloss:0.42802\teval-mlogloss:0.56373\n",
            "[50]\ttrain-mlogloss:0.42406\teval-mlogloss:0.56089\n",
            "[51]\ttrain-mlogloss:0.41970\teval-mlogloss:0.55794\n",
            "[52]\ttrain-mlogloss:0.41597\teval-mlogloss:0.55551\n",
            "[53]\ttrain-mlogloss:0.41238\teval-mlogloss:0.55308\n",
            "[54]\ttrain-mlogloss:0.40872\teval-mlogloss:0.55055\n",
            "[55]\ttrain-mlogloss:0.40476\teval-mlogloss:0.54810\n",
            "[56]\ttrain-mlogloss:0.40143\teval-mlogloss:0.54591\n",
            "[57]\ttrain-mlogloss:0.39819\teval-mlogloss:0.54368\n",
            "[58]\ttrain-mlogloss:0.39518\teval-mlogloss:0.54174\n",
            "[59]\ttrain-mlogloss:0.39242\teval-mlogloss:0.53991\n",
            "[60]\ttrain-mlogloss:0.38990\teval-mlogloss:0.53826\n",
            "[61]\ttrain-mlogloss:0.38709\teval-mlogloss:0.53630\n",
            "[62]\ttrain-mlogloss:0.38451\teval-mlogloss:0.53474\n",
            "[63]\ttrain-mlogloss:0.38207\teval-mlogloss:0.53317\n",
            "[64]\ttrain-mlogloss:0.37981\teval-mlogloss:0.53162\n",
            "[65]\ttrain-mlogloss:0.37750\teval-mlogloss:0.53012\n",
            "[66]\ttrain-mlogloss:0.37527\teval-mlogloss:0.52863\n",
            "[67]\ttrain-mlogloss:0.37302\teval-mlogloss:0.52725\n",
            "[68]\ttrain-mlogloss:0.37048\teval-mlogloss:0.52590\n",
            "[69]\ttrain-mlogloss:0.36844\teval-mlogloss:0.52465\n",
            "[70]\ttrain-mlogloss:0.36612\teval-mlogloss:0.52338\n",
            "[71]\ttrain-mlogloss:0.36386\teval-mlogloss:0.52207\n",
            "[72]\ttrain-mlogloss:0.36202\teval-mlogloss:0.52097\n",
            "[73]\ttrain-mlogloss:0.36028\teval-mlogloss:0.51993\n",
            "[74]\ttrain-mlogloss:0.35828\teval-mlogloss:0.51882\n",
            "[75]\ttrain-mlogloss:0.35647\teval-mlogloss:0.51772\n",
            "[76]\ttrain-mlogloss:0.35469\teval-mlogloss:0.51678\n",
            "[77]\ttrain-mlogloss:0.35298\teval-mlogloss:0.51571\n",
            "[78]\ttrain-mlogloss:0.35167\teval-mlogloss:0.51491\n",
            "[79]\ttrain-mlogloss:0.34972\teval-mlogloss:0.51407\n",
            "[80]\ttrain-mlogloss:0.34787\teval-mlogloss:0.51308\n",
            "[81]\ttrain-mlogloss:0.34618\teval-mlogloss:0.51221\n",
            "[82]\ttrain-mlogloss:0.34468\teval-mlogloss:0.51143\n",
            "[83]\ttrain-mlogloss:0.34271\teval-mlogloss:0.51065\n",
            "[84]\ttrain-mlogloss:0.34097\teval-mlogloss:0.50979\n",
            "[85]\ttrain-mlogloss:0.33973\teval-mlogloss:0.50910\n",
            "[86]\ttrain-mlogloss:0.33836\teval-mlogloss:0.50845\n",
            "[87]\ttrain-mlogloss:0.33679\teval-mlogloss:0.50754\n",
            "[88]\ttrain-mlogloss:0.33475\teval-mlogloss:0.50664\n",
            "[89]\ttrain-mlogloss:0.33329\teval-mlogloss:0.50592\n",
            "[90]\ttrain-mlogloss:0.33167\teval-mlogloss:0.50527\n",
            "[91]\ttrain-mlogloss:0.33053\teval-mlogloss:0.50463\n",
            "[92]\ttrain-mlogloss:0.32900\teval-mlogloss:0.50386\n",
            "[93]\ttrain-mlogloss:0.32747\teval-mlogloss:0.50325\n",
            "[94]\ttrain-mlogloss:0.32597\teval-mlogloss:0.50259\n",
            "[95]\ttrain-mlogloss:0.32451\teval-mlogloss:0.50187\n",
            "[96]\ttrain-mlogloss:0.32314\teval-mlogloss:0.50126\n",
            "[97]\ttrain-mlogloss:0.32207\teval-mlogloss:0.50083\n",
            "[98]\ttrain-mlogloss:0.32065\teval-mlogloss:0.50025\n",
            "[99]\ttrain-mlogloss:0.31964\teval-mlogloss:0.49968\n",
            "[100]\ttrain-mlogloss:0.31836\teval-mlogloss:0.49898\n",
            "[101]\ttrain-mlogloss:0.31669\teval-mlogloss:0.49831\n",
            "[102]\ttrain-mlogloss:0.31584\teval-mlogloss:0.49778\n",
            "[103]\ttrain-mlogloss:0.31469\teval-mlogloss:0.49734\n",
            "[104]\ttrain-mlogloss:0.31360\teval-mlogloss:0.49677\n",
            "[105]\ttrain-mlogloss:0.31198\teval-mlogloss:0.49618\n",
            "[106]\ttrain-mlogloss:0.31105\teval-mlogloss:0.49579\n",
            "[107]\ttrain-mlogloss:0.30987\teval-mlogloss:0.49540\n",
            "[108]\ttrain-mlogloss:0.30861\teval-mlogloss:0.49486\n",
            "[109]\ttrain-mlogloss:0.30750\teval-mlogloss:0.49450\n",
            "[110]\ttrain-mlogloss:0.30617\teval-mlogloss:0.49394\n",
            "[111]\ttrain-mlogloss:0.30524\teval-mlogloss:0.49360\n",
            "[112]\ttrain-mlogloss:0.30422\teval-mlogloss:0.49327\n",
            "[113]\ttrain-mlogloss:0.30318\teval-mlogloss:0.49284\n",
            "[114]\ttrain-mlogloss:0.30210\teval-mlogloss:0.49234\n",
            "[115]\ttrain-mlogloss:0.30106\teval-mlogloss:0.49197\n",
            "[116]\ttrain-mlogloss:0.30003\teval-mlogloss:0.49153\n",
            "[117]\ttrain-mlogloss:0.29895\teval-mlogloss:0.49117\n",
            "[118]\ttrain-mlogloss:0.29750\teval-mlogloss:0.49072\n",
            "[119]\ttrain-mlogloss:0.29638\teval-mlogloss:0.49020\n",
            "[120]\ttrain-mlogloss:0.29532\teval-mlogloss:0.48987\n",
            "[121]\ttrain-mlogloss:0.29415\teval-mlogloss:0.48937\n",
            "[122]\ttrain-mlogloss:0.29294\teval-mlogloss:0.48901\n",
            "[123]\ttrain-mlogloss:0.29130\teval-mlogloss:0.48865\n",
            "[124]\ttrain-mlogloss:0.29029\teval-mlogloss:0.48839\n",
            "[125]\ttrain-mlogloss:0.28940\teval-mlogloss:0.48807\n",
            "[126]\ttrain-mlogloss:0.28828\teval-mlogloss:0.48777\n",
            "[127]\ttrain-mlogloss:0.28725\teval-mlogloss:0.48736\n",
            "[128]\ttrain-mlogloss:0.28617\teval-mlogloss:0.48702\n",
            "[129]\ttrain-mlogloss:0.28547\teval-mlogloss:0.48676\n",
            "[130]\ttrain-mlogloss:0.28472\teval-mlogloss:0.48653\n",
            "[131]\ttrain-mlogloss:0.28397\teval-mlogloss:0.48626\n",
            "[132]\ttrain-mlogloss:0.28274\teval-mlogloss:0.48590\n",
            "[133]\ttrain-mlogloss:0.28163\teval-mlogloss:0.48552\n",
            "[134]\ttrain-mlogloss:0.28072\teval-mlogloss:0.48532\n",
            "[135]\ttrain-mlogloss:0.27981\teval-mlogloss:0.48512\n",
            "[136]\ttrain-mlogloss:0.27865\teval-mlogloss:0.48483\n",
            "[137]\ttrain-mlogloss:0.27782\teval-mlogloss:0.48459\n",
            "[138]\ttrain-mlogloss:0.27700\teval-mlogloss:0.48439\n",
            "[139]\ttrain-mlogloss:0.27576\teval-mlogloss:0.48411\n",
            "[140]\ttrain-mlogloss:0.27452\teval-mlogloss:0.48379\n",
            "[141]\ttrain-mlogloss:0.27375\teval-mlogloss:0.48347\n",
            "[142]\ttrain-mlogloss:0.27283\teval-mlogloss:0.48313\n",
            "[143]\ttrain-mlogloss:0.27172\teval-mlogloss:0.48280\n",
            "[144]\ttrain-mlogloss:0.27081\teval-mlogloss:0.48253\n",
            "[145]\ttrain-mlogloss:0.27006\teval-mlogloss:0.48236\n",
            "[146]\ttrain-mlogloss:0.26922\teval-mlogloss:0.48223\n",
            "[147]\ttrain-mlogloss:0.26814\teval-mlogloss:0.48196\n",
            "[148]\ttrain-mlogloss:0.26697\teval-mlogloss:0.48171\n",
            "[149]\ttrain-mlogloss:0.26594\teval-mlogloss:0.48153\n",
            "[150]\ttrain-mlogloss:0.26503\teval-mlogloss:0.48129\n",
            "[151]\ttrain-mlogloss:0.26415\teval-mlogloss:0.48100\n",
            "[152]\ttrain-mlogloss:0.26317\teval-mlogloss:0.48079\n",
            "[153]\ttrain-mlogloss:0.26215\teval-mlogloss:0.48058\n",
            "[154]\ttrain-mlogloss:0.26123\teval-mlogloss:0.48027\n",
            "[155]\ttrain-mlogloss:0.26052\teval-mlogloss:0.48004\n",
            "[156]\ttrain-mlogloss:0.25976\teval-mlogloss:0.47990\n",
            "[157]\ttrain-mlogloss:0.25871\teval-mlogloss:0.47967\n",
            "[158]\ttrain-mlogloss:0.25790\teval-mlogloss:0.47951\n",
            "[159]\ttrain-mlogloss:0.25727\teval-mlogloss:0.47940\n",
            "[160]\ttrain-mlogloss:0.25668\teval-mlogloss:0.47930\n",
            "[161]\ttrain-mlogloss:0.25565\teval-mlogloss:0.47922\n",
            "[162]\ttrain-mlogloss:0.25485\teval-mlogloss:0.47906\n",
            "[163]\ttrain-mlogloss:0.25404\teval-mlogloss:0.47894\n",
            "[164]\ttrain-mlogloss:0.25329\teval-mlogloss:0.47879\n",
            "[165]\ttrain-mlogloss:0.25242\teval-mlogloss:0.47853\n",
            "[166]\ttrain-mlogloss:0.25153\teval-mlogloss:0.47840\n",
            "[167]\ttrain-mlogloss:0.25085\teval-mlogloss:0.47827\n",
            "[168]\ttrain-mlogloss:0.25014\teval-mlogloss:0.47810\n",
            "[169]\ttrain-mlogloss:0.24940\teval-mlogloss:0.47790\n",
            "[170]\ttrain-mlogloss:0.24871\teval-mlogloss:0.47777\n",
            "[171]\ttrain-mlogloss:0.24799\teval-mlogloss:0.47768\n",
            "[172]\ttrain-mlogloss:0.24716\teval-mlogloss:0.47735\n",
            "[173]\ttrain-mlogloss:0.24615\teval-mlogloss:0.47719\n",
            "[174]\ttrain-mlogloss:0.24552\teval-mlogloss:0.47711\n",
            "[175]\ttrain-mlogloss:0.24487\teval-mlogloss:0.47693\n",
            "[176]\ttrain-mlogloss:0.24432\teval-mlogloss:0.47682\n",
            "[177]\ttrain-mlogloss:0.24357\teval-mlogloss:0.47667\n",
            "[178]\ttrain-mlogloss:0.24278\teval-mlogloss:0.47654\n",
            "[179]\ttrain-mlogloss:0.24208\teval-mlogloss:0.47657\n",
            "[180]\ttrain-mlogloss:0.24155\teval-mlogloss:0.47645\n",
            "[181]\ttrain-mlogloss:0.24091\teval-mlogloss:0.47621\n",
            "[182]\ttrain-mlogloss:0.24017\teval-mlogloss:0.47613\n",
            "[183]\ttrain-mlogloss:0.23939\teval-mlogloss:0.47611\n",
            "[184]\ttrain-mlogloss:0.23879\teval-mlogloss:0.47596\n",
            "[185]\ttrain-mlogloss:0.23805\teval-mlogloss:0.47582\n",
            "[186]\ttrain-mlogloss:0.23741\teval-mlogloss:0.47579\n",
            "[187]\ttrain-mlogloss:0.23678\teval-mlogloss:0.47570\n",
            "[188]\ttrain-mlogloss:0.23611\teval-mlogloss:0.47554\n",
            "[189]\ttrain-mlogloss:0.23543\teval-mlogloss:0.47541\n",
            "[190]\ttrain-mlogloss:0.23490\teval-mlogloss:0.47530\n",
            "[191]\ttrain-mlogloss:0.23433\teval-mlogloss:0.47516\n",
            "[192]\ttrain-mlogloss:0.23352\teval-mlogloss:0.47486\n",
            "[193]\ttrain-mlogloss:0.23291\teval-mlogloss:0.47475\n",
            "[194]\ttrain-mlogloss:0.23216\teval-mlogloss:0.47458\n",
            "[195]\ttrain-mlogloss:0.23113\teval-mlogloss:0.47441\n",
            "[196]\ttrain-mlogloss:0.23050\teval-mlogloss:0.47430\n",
            "[197]\ttrain-mlogloss:0.22978\teval-mlogloss:0.47421\n",
            "[198]\ttrain-mlogloss:0.22912\teval-mlogloss:0.47418\n",
            "[199]\ttrain-mlogloss:0.22873\teval-mlogloss:0.47412\n",
            "[200]\ttrain-mlogloss:0.22787\teval-mlogloss:0.47388\n",
            "[201]\ttrain-mlogloss:0.22726\teval-mlogloss:0.47372\n",
            "[202]\ttrain-mlogloss:0.22672\teval-mlogloss:0.47359\n",
            "[203]\ttrain-mlogloss:0.22619\teval-mlogloss:0.47350\n",
            "[204]\ttrain-mlogloss:0.22561\teval-mlogloss:0.47332\n",
            "[205]\ttrain-mlogloss:0.22519\teval-mlogloss:0.47325\n",
            "[206]\ttrain-mlogloss:0.22479\teval-mlogloss:0.47312\n",
            "[207]\ttrain-mlogloss:0.22416\teval-mlogloss:0.47306\n",
            "[208]\ttrain-mlogloss:0.22358\teval-mlogloss:0.47304\n",
            "[209]\ttrain-mlogloss:0.22299\teval-mlogloss:0.47295\n",
            "[210]\ttrain-mlogloss:0.22241\teval-mlogloss:0.47289\n",
            "[211]\ttrain-mlogloss:0.22181\teval-mlogloss:0.47263\n",
            "[212]\ttrain-mlogloss:0.22125\teval-mlogloss:0.47250\n",
            "[213]\ttrain-mlogloss:0.22064\teval-mlogloss:0.47252\n",
            "[214]\ttrain-mlogloss:0.22004\teval-mlogloss:0.47246\n",
            "[215]\ttrain-mlogloss:0.21962\teval-mlogloss:0.47249\n",
            "[216]\ttrain-mlogloss:0.21909\teval-mlogloss:0.47240\n",
            "[217]\ttrain-mlogloss:0.21862\teval-mlogloss:0.47228\n",
            "[218]\ttrain-mlogloss:0.21812\teval-mlogloss:0.47222\n",
            "[219]\ttrain-mlogloss:0.21755\teval-mlogloss:0.47219\n",
            "[220]\ttrain-mlogloss:0.21683\teval-mlogloss:0.47212\n",
            "[221]\ttrain-mlogloss:0.21639\teval-mlogloss:0.47204\n",
            "[222]\ttrain-mlogloss:0.21568\teval-mlogloss:0.47196\n",
            "[223]\ttrain-mlogloss:0.21506\teval-mlogloss:0.47183\n",
            "[224]\ttrain-mlogloss:0.21438\teval-mlogloss:0.47171\n",
            "[225]\ttrain-mlogloss:0.21382\teval-mlogloss:0.47171\n",
            "[226]\ttrain-mlogloss:0.21346\teval-mlogloss:0.47174\n",
            "[227]\ttrain-mlogloss:0.21269\teval-mlogloss:0.47152\n",
            "[228]\ttrain-mlogloss:0.21202\teval-mlogloss:0.47139\n",
            "[229]\ttrain-mlogloss:0.21147\teval-mlogloss:0.47122\n",
            "[230]\ttrain-mlogloss:0.21104\teval-mlogloss:0.47119\n",
            "[231]\ttrain-mlogloss:0.21072\teval-mlogloss:0.47115\n",
            "[232]\ttrain-mlogloss:0.21020\teval-mlogloss:0.47106\n",
            "[233]\ttrain-mlogloss:0.20962\teval-mlogloss:0.47102\n",
            "[234]\ttrain-mlogloss:0.20902\teval-mlogloss:0.47102\n",
            "[235]\ttrain-mlogloss:0.20845\teval-mlogloss:0.47091\n",
            "[236]\ttrain-mlogloss:0.20807\teval-mlogloss:0.47079\n",
            "[237]\ttrain-mlogloss:0.20759\teval-mlogloss:0.47080\n",
            "[238]\ttrain-mlogloss:0.20687\teval-mlogloss:0.47062\n",
            "[239]\ttrain-mlogloss:0.20633\teval-mlogloss:0.47056\n",
            "[240]\ttrain-mlogloss:0.20588\teval-mlogloss:0.47052\n",
            "[241]\ttrain-mlogloss:0.20547\teval-mlogloss:0.47048\n",
            "[242]\ttrain-mlogloss:0.20494\teval-mlogloss:0.47047\n",
            "[243]\ttrain-mlogloss:0.20435\teval-mlogloss:0.47039\n",
            "[244]\ttrain-mlogloss:0.20382\teval-mlogloss:0.47039\n",
            "[245]\ttrain-mlogloss:0.20326\teval-mlogloss:0.47034\n",
            "[246]\ttrain-mlogloss:0.20275\teval-mlogloss:0.47023\n",
            "[247]\ttrain-mlogloss:0.20229\teval-mlogloss:0.47020\n",
            "[248]\ttrain-mlogloss:0.20162\teval-mlogloss:0.47020\n",
            "[249]\ttrain-mlogloss:0.20125\teval-mlogloss:0.47014\n",
            "[250]\ttrain-mlogloss:0.20080\teval-mlogloss:0.47006\n",
            "[251]\ttrain-mlogloss:0.20020\teval-mlogloss:0.47011\n",
            "[252]\ttrain-mlogloss:0.19976\teval-mlogloss:0.47009\n",
            "[253]\ttrain-mlogloss:0.19902\teval-mlogloss:0.47002\n",
            "[254]\ttrain-mlogloss:0.19842\teval-mlogloss:0.47005\n",
            "[255]\ttrain-mlogloss:0.19778\teval-mlogloss:0.47002\n",
            "[256]\ttrain-mlogloss:0.19709\teval-mlogloss:0.46998\n",
            "[257]\ttrain-mlogloss:0.19639\teval-mlogloss:0.46990\n",
            "[258]\ttrain-mlogloss:0.19590\teval-mlogloss:0.46991\n",
            "[259]\ttrain-mlogloss:0.19554\teval-mlogloss:0.46990\n",
            "[260]\ttrain-mlogloss:0.19488\teval-mlogloss:0.46980\n",
            "[261]\ttrain-mlogloss:0.19427\teval-mlogloss:0.46970\n",
            "[262]\ttrain-mlogloss:0.19388\teval-mlogloss:0.46966\n",
            "[263]\ttrain-mlogloss:0.19348\teval-mlogloss:0.46971\n",
            "[264]\ttrain-mlogloss:0.19312\teval-mlogloss:0.46968\n",
            "[265]\ttrain-mlogloss:0.19263\teval-mlogloss:0.46965\n",
            "[266]\ttrain-mlogloss:0.19218\teval-mlogloss:0.46961\n",
            "[267]\ttrain-mlogloss:0.19179\teval-mlogloss:0.46956\n",
            "[268]\ttrain-mlogloss:0.19136\teval-mlogloss:0.46954\n",
            "[269]\ttrain-mlogloss:0.19099\teval-mlogloss:0.46953\n",
            "[270]\ttrain-mlogloss:0.19065\teval-mlogloss:0.46957\n",
            "[271]\ttrain-mlogloss:0.19013\teval-mlogloss:0.46952\n",
            "[272]\ttrain-mlogloss:0.18983\teval-mlogloss:0.46950\n",
            "[273]\ttrain-mlogloss:0.18919\teval-mlogloss:0.46948\n",
            "[274]\ttrain-mlogloss:0.18872\teval-mlogloss:0.46951\n",
            "[275]\ttrain-mlogloss:0.18813\teval-mlogloss:0.46944\n",
            "[276]\ttrain-mlogloss:0.18768\teval-mlogloss:0.46947\n",
            "[277]\ttrain-mlogloss:0.18741\teval-mlogloss:0.46945\n",
            "[278]\ttrain-mlogloss:0.18684\teval-mlogloss:0.46939\n",
            "[279]\ttrain-mlogloss:0.18644\teval-mlogloss:0.46941\n",
            "[280]\ttrain-mlogloss:0.18608\teval-mlogloss:0.46942\n",
            "[281]\ttrain-mlogloss:0.18560\teval-mlogloss:0.46935\n",
            "[282]\ttrain-mlogloss:0.18527\teval-mlogloss:0.46942\n",
            "[283]\ttrain-mlogloss:0.18484\teval-mlogloss:0.46940\n",
            "[284]\ttrain-mlogloss:0.18430\teval-mlogloss:0.46925\n",
            "[285]\ttrain-mlogloss:0.18389\teval-mlogloss:0.46929\n",
            "[286]\ttrain-mlogloss:0.18325\teval-mlogloss:0.46930\n",
            "[287]\ttrain-mlogloss:0.18286\teval-mlogloss:0.46930\n",
            "[288]\ttrain-mlogloss:0.18257\teval-mlogloss:0.46921\n",
            "[289]\ttrain-mlogloss:0.18205\teval-mlogloss:0.46920\n",
            "[290]\ttrain-mlogloss:0.18140\teval-mlogloss:0.46922\n",
            "[291]\ttrain-mlogloss:0.18094\teval-mlogloss:0.46922\n",
            "[292]\ttrain-mlogloss:0.18043\teval-mlogloss:0.46916\n",
            "[293]\ttrain-mlogloss:0.17988\teval-mlogloss:0.46912\n",
            "[294]\ttrain-mlogloss:0.17943\teval-mlogloss:0.46907\n",
            "[295]\ttrain-mlogloss:0.17911\teval-mlogloss:0.46905\n",
            "[296]\ttrain-mlogloss:0.17871\teval-mlogloss:0.46908\n",
            "[297]\ttrain-mlogloss:0.17841\teval-mlogloss:0.46904\n",
            "[298]\ttrain-mlogloss:0.17787\teval-mlogloss:0.46908\n",
            "[299]\ttrain-mlogloss:0.17747\teval-mlogloss:0.46910\n",
            "[300]\ttrain-mlogloss:0.17705\teval-mlogloss:0.46907\n",
            "[301]\ttrain-mlogloss:0.17669\teval-mlogloss:0.46910\n",
            "[302]\ttrain-mlogloss:0.17623\teval-mlogloss:0.46911\n",
            "[303]\ttrain-mlogloss:0.17597\teval-mlogloss:0.46912\n",
            "[304]\ttrain-mlogloss:0.17550\teval-mlogloss:0.46918\n",
            "[305]\ttrain-mlogloss:0.17491\teval-mlogloss:0.46917\n",
            "[306]\ttrain-mlogloss:0.17456\teval-mlogloss:0.46910\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Booster' object has no attribute 'best_ntree_limit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bf9739700ab3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# xgboostによる学習・予測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelXGB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mSubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/kagglebook/ch04-model-interface/code/runner.py\u001b[0m in \u001b[0;36mrun_train_cv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# 学習を行う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.run_name} fold {i_fold} - start training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.run_name} fold {i_fold} - end training - score {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/kagglebook/ch04-model-interface/code/runner.py\u001b[0m in \u001b[0;36mtrain_fold\u001b[0;34m(self, i_fold)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# バリデーションデータへの予測・評価を行う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mva_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/kagglebook/ch04-model-interface/code/model_xgb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, te_x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'best_ntree_limit'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    params_xgb = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'num_class': 9,\n",
        "        'max_depth': 12,\n",
        "        'eta': 0.1,\n",
        "        'min_child_weight': 10,\n",
        "        'subsample': 0.9,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'silent': 1,\n",
        "        'random_state': 71,\n",
        "        'num_round': 10000,\n",
        "        'early_stopping_rounds': 10,\n",
        "    }\n",
        "\n",
        "    params_xgb_all = dict(params_xgb)\n",
        "    params_xgb_all['num_round'] = 350\n",
        "\n",
        "    params_nn = {\n",
        "        'layers': 3,\n",
        "        # サンプルのため早く終わるように設定\n",
        "        'nb_epoch': 5,  # 1000\n",
        "        'patience': 10,\n",
        "        'dropout': 0.5,\n",
        "        'units': 512,\n",
        "    }\n",
        "\n",
        "    # 特徴量の指定\n",
        "    features = [f'feat_{i}' for i in range(1, 94)]\n",
        "\n",
        "    # xgboostによる学習・予測\n",
        "    runner = Runner('xgb1', ModelXGB, features, params_xgb)\n",
        "    runner.run_train_cv()\n",
        "    runner.run_predict_cv()\n",
        "    Submission.create_submission('xgb1')\n",
        "\n",
        "    # ニューラルネットによる学習・予測\n",
        "    runner = Runner('nn1', ModelNN, features, params_nn)\n",
        "    runner.run_train_cv()\n",
        "    runner.run_predict_cv()\n",
        "    Submission.create_submission('nn1')\n",
        "\n",
        "    '''\n",
        "    # (参考）xgboostによる学習・予測 - 学習データ全体を使う場合\n",
        "    runner = Runner('xgb1-train-all', ModelXGB, features, params_xgb_all)\n",
        "    runner.run_train_all()\n",
        "    runner.run_test_all()\n",
        "    Submission.create_submission('xgb1-train-all')\n",
        "    '''"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}