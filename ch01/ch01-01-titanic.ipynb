{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 学習データ、テストデータの読み込み\n",
    "# -----------------------------------\n",
    "# 学習データ、テストデータの読み込み\n",
    "train = pd.read_csv('../input/ch01-titanic/train.csv')\n",
    "test = pd.read_csv('../input/ch01-titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを特徴量と目的変数に分ける\n",
    "train_x = train.drop(['Survived'], axis=1)\n",
    "train_y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ebb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータは特徴量のみなので、そのままでよい\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83558ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 特徴量作成\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c14588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数PassengerIdを除外する\n",
    "train_x = train_x.drop(['PassengerId'], axis=1)\n",
    "test_x = test_x.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abe0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数Name, Ticket, Cabinを除外する\n",
    "train_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab433ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのカテゴリ変数にlabel encodingを適用する\n",
    "for c in ['Sex', 'Embarked']:\n",
    "    # 学習データに基づいてどう変換するかを定める\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_x[c].fillna('NA'))\n",
    "\n",
    "    # 学習データ、テストデータを変換する\n",
    "    train_x[c] = le.transform(train_x[c].fillna('NA'))\n",
    "    test_x[c] = le.transform(test_x[c].fillna('NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd962c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# モデル作成\n",
    "# -----------------------------------\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed34b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの作成および学習データを与えての学習\n",
    "model = XGBClassifier(n_estimators=20, random_state=71)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cf274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの予測値を確率で出力する\n",
    "pred = model.predict_proba(test_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31981dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの予測値を二値に変換する\n",
    "pred_label = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e81e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用ファイルの作成\n",
    "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
    "submission.to_csv('submission_first.csv', index=False)\n",
    "# スコア：0.7799（本書中の数値と異なる可能性があります）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# バリデーション\n",
    "# -----------------------------------\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8df55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各foldのスコアを保存するリスト\n",
    "scores_accuracy = []\n",
    "scores_logloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションを行う\n",
    "# 学習データを4つに分割し、うち1つをバリデーションデータとすることを、バリデーションデータを変えて繰り返す\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_x):\n",
    "    # 学習データを学習データとバリデーションデータに分ける\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "    # モデルの学習を行う\n",
    "    model = XGBClassifier(n_estimators=20, random_state=71)\n",
    "    model.fit(tr_x, tr_y)\n",
    "\n",
    "    # バリデーションデータの予測値を確率で出力する\n",
    "    va_pred = model.predict_proba(va_x)[:, 1]\n",
    "\n",
    "    # バリデーションデータでのスコアを計算する\n",
    "    logloss = log_loss(va_y, va_pred)\n",
    "    accuracy = accuracy_score(va_y, va_pred > 0.5)\n",
    "\n",
    "    # そのfoldのスコアを保存する\n",
    "    scores_logloss.append(logloss)\n",
    "    scores_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各foldのスコアの平均を出力する\n",
    "logloss = np.mean(scores_logloss)\n",
    "accuracy = np.mean(scores_accuracy)\n",
    "print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')\n",
    "# logloss: 0.4270, accuracy: 0.8148（本書中の数値と異なる可能性があります）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# モデルチューニング\n",
    "# -----------------------------------\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ad64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チューニング候補とするパラメータを準備する\n",
    "param_space = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1.0, 2.0, 4.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179aa3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索するハイパーパラメータの組み合わせ\n",
    "param_combinations = itertools.product(param_space['max_depth'], param_space['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fdf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各パラメータの組み合わせ、それに対するスコアを保存するリスト\n",
    "params = []\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各パラメータの組み合わせごとに、クロスバリデーションで評価を行う\n",
    "for max_depth, min_child_weight in param_combinations:\n",
    "\n",
    "    score_folds = []\n",
    "    # クロスバリデーションを行う\n",
    "    # 学習データを4つに分割し、うち1つをバリデーションデータとすることを、バリデーションデータを変えて繰り返す\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=123456)\n",
    "    for tr_idx, va_idx in kf.split(train_x):\n",
    "        # 学習データを学習データとバリデーションデータに分ける\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "        # モデルの学習を行う\n",
    "        model = XGBClassifier(n_estimators=20, random_state=71,\n",
    "                              max_depth=max_depth, min_child_weight=min_child_weight)\n",
    "        model.fit(tr_x, tr_y)\n",
    "\n",
    "        # バリデーションデータでのスコアを計算し、保存する\n",
    "        va_pred = model.predict_proba(va_x)[:, 1]\n",
    "        logloss = log_loss(va_y, va_pred)\n",
    "        score_folds.append(logloss)\n",
    "\n",
    "    # 各foldのスコアを平均する\n",
    "    score_mean = np.mean(score_folds)\n",
    "\n",
    "    # パラメータの組み合わせ、それに対するスコアを保存する\n",
    "    params.append((max_depth, min_child_weight))\n",
    "    scores.append(score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5e8ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 最もスコアが良いものをベストなパラメータとする\n",
    "best_idx = np.argsort(scores)[0]\n",
    "best_param = params[best_idx]\n",
    "print(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')\n",
    "# max_depth=7, min_child_weight=2.0のスコアが最もよかった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# ロジスティック回帰用の特徴量の作成\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac945dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元データをコピーする\n",
    "train_x2 = train.drop(['Survived'], axis=1)\n",
    "test_x2 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数PassengerIdを除外する\n",
    "train_x2 = train_x2.drop(['PassengerId'], axis=1)\n",
    "test_x2 = test_x2.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数Name, Ticket, Cabinを除外する\n",
    "train_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encodingを行う\n",
    "cat_cols = ['Sex', 'Embarked', 'Pclass']\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "ohe.fit(train_x2[cat_cols].fillna('NA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259562bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encodingのダミー変数の列名を作成する\n",
    "ohe_columns = []\n",
    "for i, c in enumerate(cat_cols):\n",
    "    ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encodingによる変換を行う\n",
    "ohe_train_x2 = pd.DataFrame(ohe.transform(train_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
    "ohe_test_x2 = pd.DataFrame(ohe.transform(test_x2[cat_cols].fillna('NA')), columns=ohe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding済みの変数を除外する\n",
    "train_x2 = train_x2.drop(cat_cols, axis=1)\n",
    "test_x2 = test_x2.drop(cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encodingで変換された変数を結合する\n",
    "train_x2 = pd.concat([train_x2, ohe_train_x2], axis=1)\n",
    "test_x2 = pd.concat([test_x2, ohe_test_x2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値変数の欠損値を学習データの平均で埋める\n",
    "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "for col in num_cols:\n",
    "    train_x2[col].fillna(train_x2[col].mean(), inplace=True)\n",
    "    test_x2[col].fillna(train_x2[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数Fareを対数変換する\n",
    "train_x2['Fare'] = np.log1p(train_x2['Fare'])\n",
    "test_x2['Fare'] = np.log1p(test_x2['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# アンサンブル\n",
    "# -----------------------------------\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboostモデル\n",
    "model_xgb = XGBClassifier(n_estimators=20, random_state=71)\n",
    "model_xgb.fit(train_x, train_y)\n",
    "pred_xgb = model_xgb.predict_proba(test_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰モデル\n",
    "# xgboostモデルとは異なる特徴量を入れる必要があるので、別途train_x2, test_x2を作成した\n",
    "model_lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "model_lr.fit(train_x2, train_y)\n",
    "pred_lr = model_lr.predict_proba(test_x2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値の加重平均をとる\n",
    "pred = pred_xgb * 0.8 + pred_lr * 0.2\n",
    "pred_label = np.where(pred > 0.5, 1, 0)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
