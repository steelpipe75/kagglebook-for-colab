{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002f0a5",
   "metadata": {},
   "source": [
    "train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a546c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/train_preprocessed_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a96426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a314fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowの警告抑制\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f37dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# ニューラルネットのパラメータチューニングの例\n",
    "# -----------------------------------\n",
    "from hyperopt import hp\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import ReLU, PReLU\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本となるパラメータ\n",
    "base_param = {\n",
    "    'input_dropout': 0.0,\n",
    "    'hidden_layers': 3,\n",
    "    'hidden_units': 96,\n",
    "    'hidden_activation': 'relu',\n",
    "    'hidden_dropout': 0.2,\n",
    "    'batch_norm': 'before_act',\n",
    "    'optimizer': {'type': 'adam', 'lr': 0.001},\n",
    "    'batch_size': 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索するパラメータの空間を指定する\n",
    "param_space = {\n",
    "    'input_dropout': hp.quniform('input_dropout', 0, 0.2, 0.05),\n",
    "    'hidden_layers': hp.quniform('hidden_layers', 2, 4, 1),\n",
    "    'hidden_units': hp.quniform('hidden_units', 32, 256, 32),\n",
    "    'hidden_activation': hp.choice('hidden_activation', ['prelu', 'relu']),\n",
    "    'hidden_dropout': hp.quniform('hidden_dropout', 0, 0.3, 0.05),\n",
    "    'batch_norm': hp.choice('batch_norm', ['before_act', 'no']),\n",
    "    'optimizer': hp.choice('optimizer',\n",
    "                           [{'type': 'adam',\n",
    "                             'lr': hp.loguniform('adam_lr', np.log(0.00001), np.log(0.01))},\n",
    "                            {'type': 'sgd',\n",
    "                             'lr': hp.loguniform('sgd_lr', np.log(0.00001), np.log(0.01))}]),\n",
    "    'batch_size': hp.quniform('batch_size', 32, 128, 32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "\n",
    "        # パラメータ\n",
    "        input_dropout = self.params['input_dropout']\n",
    "        hidden_layers = int(self.params['hidden_layers'])\n",
    "        hidden_units = int(self.params['hidden_units'])\n",
    "        hidden_activation = self.params['hidden_activation']\n",
    "        hidden_dropout = self.params['hidden_dropout']\n",
    "        batch_norm = self.params['batch_norm']\n",
    "        optimizer_type = self.params['optimizer']['type']\n",
    "        optimizer_lr = self.params['optimizer']['lr']\n",
    "        batch_size = int(self.params['batch_size'])\n",
    "\n",
    "        # 標準化\n",
    "        self.scaler = StandardScaler()\n",
    "        tr_x = self.scaler.fit_transform(tr_x)\n",
    "        va_x = self.scaler.transform(va_x)\n",
    "\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # 入力層\n",
    "        self.model.add(Dropout(input_dropout, input_shape=(tr_x.shape[1],)))\n",
    "\n",
    "        # 中間層\n",
    "        for i in range(hidden_layers):\n",
    "            self.model.add(Dense(hidden_units))\n",
    "            if batch_norm == 'before_act':\n",
    "                self.model.add(BatchNormalization())\n",
    "            if hidden_activation == 'prelu':\n",
    "                self.model.add(PReLU())\n",
    "            elif hidden_activation == 'relu':\n",
    "                self.model.add(ReLU())\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            self.model.add(Dropout(hidden_dropout))\n",
    "\n",
    "        # 出力層\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # オプティマイザ\n",
    "        if optimizer_type == 'sgd':\n",
    "            optimizer = SGD(lr=optimizer_lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        elif optimizer_type == 'adam':\n",
    "            optimizer = Adam(lr=optimizer_lr, beta_1=0.9, beta_2=0.999, decay=0.)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # 目的関数、評価指標などの設定\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # エポック数、アーリーストッピング\n",
    "        # あまりepochを大きくすると、小さい学習率のときに終わらないことがあるので注意\n",
    "        nb_epoch = 200\n",
    "        patience = 20\n",
    "        early_stopping = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "\n",
    "        # 学習の実行\n",
    "        history = self.model.fit(tr_x, tr_y,\n",
    "                                 epochs=nb_epoch,\n",
    "                                 batch_size=batch_size, verbose=1,\n",
    "                                 validation_data=(va_x, va_y),\n",
    "                                 callbacks=[early_stopping])\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 予測\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.model.predict(x)\n",
    "        y_pred = y_pred.flatten()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08679661",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "パラメータチューニングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ed0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    # パラメータセットを指定したときに最小化すべき関数を指定する\n",
    "    # モデルのパラメータ探索においては、モデルにパラメータを指定して学習・予測させた場合のスコアとする\n",
    "    model = MLP(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    # 情報を記録しておく\n",
    "    history.append((params, score))\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af151c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperoptによるパラメータ探索の実行\n",
    "max_evals = 10\n",
    "trials = Trials()\n",
    "history = []\n",
    "fmin(score, param_space, algo=tpe.suggest, trials=trials, max_evals=max_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記録した情報からパラメータとスコアを出力する\n",
    "# trialsからも情報が取得できるが、パラメータを取得しにくい\n",
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params:{best[0]}, score:{best[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
